Mathm Alkaabi
Approximate Differential Privacy
Pseudocode 
Assumptions:
We use the Gaussian mechanism to generate noise.
The result will be F(x) = f(x) + N(ÏƒÂ²), where f(x) is the function and N is the noise generated from the Gaussian distribution with center 0 and variance ÏƒÂ² (sigma squared).
Sigma squared (ÏƒÂ²) =  2s2log(1.25Î´)ğœ€2
The datasetâ€™s attributes are real-valued and continuous.
The failure probability (delta - Î´) is set to 1n2 , where n is the size of the dataset. 
The privacy budget (epsilon - ğœ€) is equal to or less than 1 since we use the classic Gaussian mechanism.
Inputs: 
f(x) - function with input dataset that needs to be privatized
epsilon - privacy budget (ğœ€)
delta - failure probability (Î´)
s - sensitivity of function f(x)

	Output: 
F(x) (result) - Approximate differential private result of f(x)

ADP( f(x), epsilon, delta, s):
	   // 1. Calculate the variance for Gaussian noise
	   sigmaSquared = (2 * s^2 * log(1.25 / delta)) / epsilon^2

	  // 2. Get noise from the Gaussian distribution 
	  gNoise = Gaussian(0, sqrt(sigmaSquared))

	 // 3. Compute the privacy result by adding noise, and return it
	 result = f(x) + gNoise		
	 return result 
Struggles: My main struggles were understanding the failure probability, where the privacy guarantees may not hold and fail, and the reasoning behind it and why itâ€™s set as 1 / n^2, where n is the dataset size. Another struggle I had was how and why the Gaussian distribution is used (I followed the https://programming-dp.com/ch6.html# example). The actual code and initial equations werenâ€™t difficult to understand, since it's just inputting values, but the underlying reasons why we use these equations and values to generate noise is the source of my confusion. 
